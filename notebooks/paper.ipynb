{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproducing Main Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%env HF_TOKEN=<your HF token here>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "\n",
    "# Pick one of the following datasets:\n",
    "dataset: Literal[\"visionarena\", \"searcharena\", \"lmarena\"] = \"lmarena\"\n",
    "\n",
    "# Pick one of the following rating systems:\n",
    "rating_system: Literal[\"elo\", \"trueskill\", \"glicko2\", \"bt\"] = \"elo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "\n",
    "from lmarena_draws.rating import EloRatingSystem, TrueSkillRatingSystem, Glicko2RatingSystem, OnlineBTRatingSystem  \n",
    "\n",
    "match rating_system:\n",
    "    case \"elo\":\n",
    "        sys_cls = EloRatingSystem\n",
    "    case \"trueskill\":\n",
    "        sys_cls = TrueSkillRatingSystem\n",
    "    case \"glicko2\":\n",
    "        sys_cls = Glicko2RatingSystem\n",
    "    case \"bt\":\n",
    "        sys_cls = OnlineBTRatingSystem\n",
    "    case _:\n",
    "        raise ValueError(f\"Invalid rating system: {rating_system}\")\n",
    "\n",
    "match dataset:\n",
    "    case \"visionarena\":\n",
    "        split = \"train\"\n",
    "        judge_column = \"judge\"\n",
    "        ds = load_dataset(\"lmarena-ai/VisionArena-Battle\")\n",
    "    case \"searcharena\":\n",
    "        split = \"test\"\n",
    "        judge_column = \"judge\"\n",
    "        ds = load_dataset(\"lmarena-ai/search-arena-24k\")\n",
    "    case \"lmarena\":\n",
    "        split = \"train\"\n",
    "        judge_column = \"judge_hash\"\n",
    "        ds = load_dataset(\"lmarena-ai/arena-human-preference-100k\")\n",
    "    case _:\n",
    "        raise ValueError(f\"Invalid dataset: {dataset}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df = ds[split]\n",
    "df = df.select_columns([\"model_a\", \"model_b\", \"winner\", judge_column])\n",
    "\n",
    "models = list(set(list(df[\"model_a\"])))\n",
    "models.extend(list(set(list(df[\"model_b\"]))))\n",
    "models = list(set(models))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building battles...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/106134 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 106134/106134 [00:03<00:00, 33593.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Build battles\n",
    "from lmarena_draws.rating import Battle, BattleOutcome\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "battles = []\n",
    "\n",
    "print(\"Building battles...\")\n",
    "\n",
    "for row in tqdm(df):\n",
    "    model_a = row[\"model_a\"]\n",
    "    model_b = row[\"model_b\"]\n",
    "    winner = row[\"winner\"]\n",
    "    sub_outcome = None\n",
    "\n",
    "    if winner is None:\n",
    "        continue\n",
    "\n",
    "    if winner == \"model_a\":\n",
    "        outcome = BattleOutcome.LOSS\n",
    "    elif winner == \"model_b\":\n",
    "        outcome = BattleOutcome.WIN\n",
    "    elif winner == \"tie\":\n",
    "        outcome = BattleOutcome.DRAW\n",
    "        sub_outcome = None\n",
    "    elif \"bothbad\" in winner:\n",
    "        outcome = BattleOutcome.DRAW\n",
    "        sub_outcome = \"bothbad\"\n",
    "    else:\n",
    "        continue\n",
    "\n",
    "    battles.append(\n",
    "        Battle(\n",
    "            model_a=model_a,\n",
    "            model_b=model_b,\n",
    "            outcome=outcome,\n",
    "            sub_outcome=sub_outcome,    \n",
    "            user_id=row[judge_column],\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106134"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(battles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acc. Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best draw margin: 0.2, best accuracy: 0.38193802191398346\n",
      "w/draw updates:  0.36791845908897614\n",
      "w/o draw updates:  0.3815203382035336\n",
      "random omission:  0.36712437327017583\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "draw_pct = np.mean([x.outcome == BattleOutcome.DRAW for x in battles])\n",
    "burn_in = int(0.05 * len(battles))\n",
    "best_draw_margin = None\n",
    "best_acc = 0\n",
    "\n",
    "# Grid search for best draw margin\n",
    "for draw_margin in np.linspace(0.05, 0.45, 9):\n",
    "    sys = sys_cls(models, draw_margin=draw_margin)\n",
    "    update_categories = [BattleOutcome.WIN, BattleOutcome.DRAW, BattleOutcome.LOSS]\n",
    "\n",
    "    results = sys.prequential_losses(\n",
    "        battles[:burn_in],\n",
    "        burn_in=0,\n",
    "        update_categories=update_categories,\n",
    "        disable_tqdm=True,\n",
    "    )\n",
    "\n",
    "    acc = results.macro_accuracy\n",
    "\n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_draw_margin = draw_margin\n",
    "\n",
    "print(f\"best draw margin: {best_draw_margin}, best accuracy: {best_acc}\")\n",
    "\n",
    "sys = sys_cls(models, draw_margin=best_draw_margin)\n",
    "update_categories = [BattleOutcome.WIN, BattleOutcome.DRAW, BattleOutcome.LOSS]\n",
    "results = sys.prequential_losses(\n",
    "    battles,\n",
    "    burn_in=burn_in,\n",
    "    update_categories=update_categories,\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "\n",
    "print(\"w/draw updates: \", results.macro_accuracy)\n",
    "\n",
    "sys = sys_cls(models, draw_margin=best_draw_margin)\n",
    "update_categories = [BattleOutcome.WIN, BattleOutcome.LOSS]  # no draw updates\n",
    "\n",
    "results = sys.prequential_losses(\n",
    "    battles,\n",
    "    burn_in=burn_in,\n",
    "    update_categories=update_categories,\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "\n",
    "print(\"w/o draw updates: \", results.macro_accuracy)\n",
    "\n",
    "sys = sys_cls(models, draw_margin=best_draw_margin)\n",
    "update_categories = [BattleOutcome.WIN, BattleOutcome.DRAW, BattleOutcome.LOSS]\n",
    "results = sys.prequential_losses(\n",
    "    battles,\n",
    "    burn_in=burn_in,\n",
    "    update_categories=update_categories,\n",
    "    disable_tqdm=True,\n",
    "    dropout_rate=draw_pct,\n",
    ")\n",
    "\n",
    "print(\"random omission: \", results.macro_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WL-Acc. Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w/draw updates:  0.5711721288263603\n",
      "w/o draw updates:  0.5831818726363294\n",
      "random omission:  0.5720712459472387\n"
     ]
    }
   ],
   "source": [
    "draw_pct = np.mean([x.outcome == BattleOutcome.DRAW for x in battles])\n",
    "burn_in = int(0.05 * len(battles))\n",
    "best_draw_margin = 0.0\n",
    "\n",
    "sys = sys_cls(models, draw_margin=best_draw_margin)\n",
    "update_categories = [BattleOutcome.WIN, BattleOutcome.DRAW, BattleOutcome.LOSS]\n",
    "eval_categories = [BattleOutcome.WIN, BattleOutcome.LOSS]\n",
    "results = sys.prequential_losses(\n",
    "    battles,\n",
    "    no_ties=True,\n",
    "    burn_in=burn_in,\n",
    "    eval_categories=eval_categories,\n",
    "    update_categories=update_categories,\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "\n",
    "print(\"w/draw updates: \", results.macro_accuracy)\n",
    "\n",
    "sys = sys_cls(models, draw_margin=best_draw_margin)\n",
    "update_categories = [BattleOutcome.WIN, BattleOutcome.LOSS]  # no draw updates\n",
    "eval_categories = [BattleOutcome.WIN, BattleOutcome.LOSS]\n",
    "results = sys.prequential_losses(\n",
    "    battles,\n",
    "    no_ties=True,\n",
    "    burn_in=burn_in,\n",
    "    eval_categories=eval_categories,\n",
    "    update_categories=update_categories,\n",
    "    disable_tqdm=True,\n",
    ")\n",
    "\n",
    "print(\"w/o draw updates: \", results.macro_accuracy)\n",
    "\n",
    "sys = sys_cls(models, draw_margin=best_draw_margin)\n",
    "update_categories = [BattleOutcome.WIN, BattleOutcome.DRAW, BattleOutcome.LOSS]\n",
    "eval_categories = [BattleOutcome.WIN, BattleOutcome.LOSS]\n",
    "results = sys.prequential_losses(\n",
    "    battles,\n",
    "    no_ties=True,\n",
    "    burn_in=burn_in,\n",
    "    eval_categories=eval_categories,\n",
    "    update_categories=update_categories,\n",
    "    disable_tqdm=True,\n",
    "    dropout_rate=draw_pct,\n",
    ")\n",
    "\n",
    "print(\"random omission: \", results.macro_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
